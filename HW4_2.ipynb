{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panzershracker/Deep-learning-in-comp.-vision/blob/master/HW4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mMFQQHCC254",
        "colab_type": "text"
      },
      "source": [
        "#Домашнее задание к уроку №4. Евдокимов Алексей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP_j1BdoDF2l",
        "colab_type": "text"
      },
      "source": [
        "# Задание:\n",
        "\n",
        "Обучить модель семантической сегментации (человек-vs-фон) на подмножестве датасета MS COCO.\n",
        "Библиотеки: [Python, Tensorflow]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt-Y_XwlBVKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEG4QUHqB_hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import skimage.io as io\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NbUjfwHCNRe",
        "colab_type": "text"
      },
      "source": [
        "#Загрузка датасета COCO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FntN3iQDtj0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6hsleHMtgB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38cdsr5hT1KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOrQAeuqCK8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load:\n",
        "  !cd data && wget http://images.cocodataset.org/zips/train2017.zip \n",
        "  !cd data && wget http://images.cocodataset.org/zips/val2017.zip \n",
        "  !cd data && wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUXjc0nbr4mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load:\n",
        "  !cd data && unzip -q train2017.zip\n",
        "  !cd data && unzip -q val2017.zip\n",
        "  !cd data && unzip -q annotations_trainval2017.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcbTE2Tyr46E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load:\n",
        "  !cd data && git clone https://github.com/cocodataset/cocoapi\n",
        "  !cd data/cocoapi/PythonAPI && make"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mY_1URiJahs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install --upgrade pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLfONlhZDNYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COCO_ROOT = './data/'\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, os.path.join(COCO_ROOT, 'cocoapi/PythonAPI'))\n",
        "\n",
        "from pycocotools.coco import COCO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk_3fCUdOl3I",
        "colab_type": "text"
      },
      "source": [
        "# Сласс Dataset для сегментации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7P-WhL7IpJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset():\n",
        "  \n",
        "  def crop_image(self, img, inp_size, random_crop=False):\n",
        "\n",
        "    shape = tf.shape(img)\n",
        "    pad = (\n",
        "        [0, tf.maximum(inp_size - shape[0], 0)],\n",
        "        [0, tf.maximum(inp_size - shape[1], 0)],\n",
        "        [0,0]\n",
        "    )\n",
        "    img = tf.pad(img, pad)\n",
        "\n",
        "    if random_crop:\n",
        "      img = tf.image.random_crop(img, (inp_size, inp_size, shape[2]))\n",
        "    else:\n",
        "      shape = tf.shape(img)\n",
        "      ho = (shape[0] - inp_size) // 2\n",
        "      wo = (shape[1] - inp_size) // 2\n",
        "      img = img[ho : ho+inp_size, wo : wo+inp_size, :]\n",
        "\n",
        "    return img\n",
        "\n",
        "  def train_dataset(self, batch_size, epochs, inp_size):\n",
        "\n",
        "    def item_to_image(item):\n",
        "      random_crop = True\n",
        "      img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "      img_combined = self.crop_image(img_combined, inp_size, random_crop)\n",
        "\n",
        "      img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255)\n",
        "      mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "\n",
        "      return img, mask_class\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "    dataset = dataset.shuffle(buffer_size=len(self.img_list))\n",
        "    dataset = dataset.map(item_to_image)\n",
        "    dataset = dataset.repeat(epochs)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  def val_dataset(self, batch_size, inp_size):\n",
        "\n",
        "    def item_to_image(item):\n",
        "      random_crop = False\n",
        "      img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "      img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "\n",
        "      img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255)\n",
        "      mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "    dataset = dataset.map(item_to_image)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxpZiEYcfEOT",
        "colab_type": "text"
      },
      "source": [
        "#Класс для датасета COCO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jeArYZ5fN8V",
        "colab_type": "text"
      },
      "source": [
        "Класс наследуется от Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXv7zRhQfH9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class COCO_dataset(Dataset):\n",
        "\n",
        "  def __init__(self, sublist):\n",
        "\n",
        "    ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_' + sublist + '2017.json')\n",
        "    self.coco = COCO(ann_file_fpath)\n",
        "    self.cat_ids = self.coco.getCatIds(catNms=['person'])\n",
        "    self.img_list = self.coco.getImgIds(catIds=self.cat_ids)\n",
        "    \n",
        "  def read_images(self, img_id):\n",
        "    img_id = int(img_id.numpy())\n",
        "    img_data = self.coco.loadImgs(img_id)[0]\n",
        "    img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n",
        "\n",
        "    img = io.imread(os.path.join(COCO_ROOT, img_fname))\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.tile(img[..., None], (1,1,3))\n",
        "\n",
        "    ann_ids = self.coco.getAnnIds(imgIds=img_data['id'], catIds=self.cat_ids, iscrowd=None)\n",
        "    anns = self.coco.loadAnns(ann_ids)\n",
        "    mask_class = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    for i in range(len(anns)):\n",
        "      mask_class += self.coco.annToMask(anns[i])\n",
        "    mask_class = (mask_class > 0).astype(np.uint8)\n",
        "\n",
        "    img_combined = np.concatenate([img, mask_class[..., None]], axis=2)\n",
        "\n",
        "    return img_combined"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujW32wmkpAYj",
        "colab_type": "code",
        "outputId": "ab7dba4c-3c09-4370-f5d1-e0ec7de05811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "coco_train = COCO_dataset('train')\n",
        "coco_valid = COCO_dataset('val')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=23.84s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.82s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjv0yn5ydJ1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INP_SIZE = 256\n",
        "EPOCHS = 1\n",
        "BATCH = 128\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je9xirs0lsxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = coco_train.train_dataset(batch_size=BATCH, epochs=EPOCHS, inp_size=INP_SIZE)\n",
        "test = coco_valid.train_dataset(batch_size=BATCH, epochs=EPOCHS, inp_size=INP_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQix7Ix7_w1a",
        "colab_type": "code",
        "outputId": "d83b23f6-6ae4-441e-c8ee-57a69234239e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "type(train), type(test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensorflow.python.data.ops.dataset_ops.BatchDataset,\n",
              " tensorflow.python.data.ops.dataset_ops.BatchDataset)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmPZN7T0Xw4g",
        "colab_type": "text"
      },
      "source": [
        "#Создание модели U-net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhkbIL0MUnGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model():\n",
        "  x = tf.keras.layers.Input((256,256,3))\n",
        "\n",
        "  out = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
        "  out1 = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(out)\n",
        "  out = tf.keras.layers.MaxPool2D((2,2))(out1)\n",
        "\n",
        "  # out = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(out)\n",
        "  out2 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(out)\n",
        "  out = tf.keras.layers.MaxPool2D((2,2))(out2)\n",
        "\n",
        "  # out = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(out)\n",
        "  out3 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(out)\n",
        "  out = tf.keras.layers.MaxPool2D((2,2))(out3)\n",
        "\n",
        "  # out = tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu')(out)\n",
        "  out4 = tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu')(out)\n",
        "  out = tf.keras.layers.MaxPool2D((2,2))(out4)  \n",
        "\n",
        "  # out = tf.keras.layers.Conv2D(1024, (3,3), padding='same', activation='relu', )(out)\n",
        "  # out = tf.keras.layers.Conv2D(1024, (3,3), padding='same', activation='relu', )(out)\n",
        "\n",
        "  out = tf.keras.layers.Conv2DTranspose(512, (3,3), strides=(2,2), padding='same', activation='relu')(out)\n",
        "  out = tf.concat([out4, out], axis=3)\n",
        "\n",
        "  # out = tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu')(out)\n",
        "  out = tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu')(out)  \n",
        "\n",
        "  out = tf.keras.layers.Conv2DTranspose(256, (3,3), strides=(2,2), padding='same', activation='relu')(out)\n",
        "  out = tf.concat([out3, out], axis=3)\n",
        "\n",
        "  out = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(out)\n",
        "  # out = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(out)  \n",
        "\n",
        "  out = tf.keras.layers.Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', activation='relu')(out)\n",
        "  out = tf.concat([out2, out], axis=3)\n",
        "\n",
        "  out = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(out)\n",
        "  # out = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(out) \n",
        "\n",
        "  out = tf.keras.layers.Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', activation='relu')(out)\n",
        "  out = tf.concat([out1, out], axis=3)\n",
        "\n",
        "  out = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(out)\n",
        "  out = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(out)\n",
        "  out = tf.keras.layers.Conv2D(1, (3,3), padding='same', activation='sigmoid')(out)\n",
        "\n",
        "  return tf.keras.Model(inputs=x, outputs=out)\n",
        "\n",
        "model = model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSwrRXa-ggJk",
        "colab_type": "text"
      },
      "source": [
        "#Схематическая визуализация сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRo5GD8Ngd2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.keras.utils.plot_model(model, show_shapes=1, dpi=72)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkaNNIuRh9hl",
        "colab_type": "text"
      },
      "source": [
        "#Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj-mW6K_h5sR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ef7dee6-5a13-4cd3-be06-817ec84451ef"
      },
      "source": [
        "%%time \n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='binary_crossentropy',\n",
        "    metrics='accuracy'\n",
        ")\n",
        "\n",
        "hist = model.fit(train, epochs=EPOCHS)\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 13/500 [..............................] - ETA: 7:11:24 - loss: 0.5545 - accuracy: 0.7661"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMWm24cJCgOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}